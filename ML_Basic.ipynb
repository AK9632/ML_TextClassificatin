{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ML_Basic.ipynb","provenance":[],"collapsed_sections":["7XFXbeKKP997","bUs7PfnlWGWX","NP-nAx84Ybw6","EpTuzpMO0X59","5nbdGVKvJ1X2"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WL3FmZOZWqFP","executionInfo":{"status":"ok","timestamp":1620598218341,"user_tz":-330,"elapsed":32253,"user":{"displayName":"Anvesh Kiran","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjOhw_iYLoY6AZqKmJEWDXO_3Yv2PYAk9BRNjsK8Q=s64","userId":"09289906135724588146"}},"outputId":"ce7ab888-71a8-4e91-d2d3-83b0f4d6ad54"},"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"7XFXbeKKP997"},"source":["\n","# **PRE-PROCESSING**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S4XM2kLJY9H5","executionInfo":{"status":"ok","timestamp":1620598228499,"user_tz":-330,"elapsed":5975,"user":{"displayName":"Anvesh Kiran","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjOhw_iYLoY6AZqKmJEWDXO_3Yv2PYAk9BRNjsK8Q=s64","userId":"09289906135724588146"}},"outputId":"b84a5aaa-df90-43ca-b418-dbba53621e96"},"source":["############################################################# PREPROCESSING\n","\n","import numpy as np \n","import pandas as pd \n","import nltk\n","import string\n","\n","from nltk.corpus import stopwords\n","nltk.download('stopwords')\n","stop = stopwords.words('english')\n","\n","def remove_stopwords(text) :\n","  arr_of_words=text.split()\n","  return_text=''\n","  for word in arr_of_words :\n","    if word not in stop :\n","      return_text+=word\n","      return_text+=' '\n","  return return_text\n","\n","def remove_punctuations(text):\n","    for punctuation in string.punctuation:\n","        text = text.replace(punctuation, '')\n","    return text\n","\n","def make_lower(text) :\n","  lower_text=text.lower()\n","  return lower_text\n","\n","def remove_numbers(text) :\n","  alpha_text=''\n","  arr_of_words=text.split()\n","  for i in arr_of_words :\n","    try :\n","      x=int(i)\n","    except ValueError :\n","      alpha_text+=i\n","      alpha_text+=' '\n","  return alpha_text\n","\n","def deal_media(text) :\n","  arr_of_words=text.split()\n","  final_text=''\n","  for i in arr_of_words :\n","    if 'http://' in i :\n","      word='aszxdcfvgb'\n","    else :\n","      word=i\n","    final_text+=word\n","    final_text+=' '\n","  return final_text\n","\n","def remove_nan(text) :\n","  text = text.replace(' nan ', '')\n","  return text\n","\n","\n","\n","train_df = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/ML_Project/ML_data/train.csv\") \n","test_df = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/ML_Project/ML_data/test.csv\")\n","\n","#train_df = pd.read_csv(\"/content/drive/My Drive/ML_data/train.csv\") \n","#test_df = pd.read_csv(\"/content/drive/My Drive/ML_data/test.csv\")\n","\n","#adding location to text\n","train_df[\"text\"] = train_df[\"text\"] + ' ' + train_df[\"location\"].astype(str) +' '\n","test_df[\"text\"] = test_df[\"text\"] + ' ' + test_df[\"location\"].astype(str) +' '\n","\n","\n","train_df[\"text\"] = train_df[\"text\"].apply(remove_nan)\n","train_df[\"text\"] = train_df[\"text\"].apply(deal_media)\n","train_df[\"text\"] = train_df[\"text\"].apply(remove_stopwords)\n","train_df[\"text\"] = train_df[\"text\"].apply(remove_punctuations)\n","train_df[\"text\"] = train_df[\"text\"].apply(make_lower)\n","train_df[\"text\"] = train_df[\"text\"].apply(remove_numbers)\n","\n","test_df[\"text\"] = test_df[\"text\"].apply(remove_nan)\n","test_df[\"text\"] = test_df[\"text\"].apply(deal_media)\n","test_df[\"text\"] = test_df[\"text\"].apply(remove_stopwords)\n","test_df[\"text\"] = test_df[\"text\"].apply(remove_punctuations)\n","test_df[\"text\"] = test_df[\"text\"].apply(make_lower)\n","test_df[\"text\"] = test_df[\"text\"].apply(remove_numbers)\n","\n","\n","x_train=train_df[\"text\"]\n","y_train=train_df[\"target\"]\n","x_test=test_df[\"text\"]\n","\n","\n","print(\"Preprocessing done\")\n","print(\"\")\n","print(\"Locations added to text\")\n","print(\"Links were removed\")\n","print(\"Stopwords removed\")\n","print(\"punctuations removed\")\n","print(\"Numbers removed\")\n","print(\"Lowered the text\")\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","Preprocessing done\n","\n","Locations added to text\n","Links were removed\n","Stopwords removed\n","punctuations removed\n","Numbers removed\n","Lowered the text\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"bUs7PfnlWGWX"},"source":["\n","# **VECTORIZATION**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ty4jaZQTP7fJ","executionInfo":{"status":"ok","timestamp":1620598238468,"user_tz":-330,"elapsed":1619,"user":{"displayName":"Anvesh Kiran","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjOhw_iYLoY6AZqKmJEWDXO_3Yv2PYAk9BRNjsK8Q=s64","userId":"09289906135724588146"}},"outputId":"8d114c1c-3511-43ed-cb5d-2bb79d00b8e6"},"source":["from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","\n","cv = CountVectorizer()\n","tv = TfidfVectorizer()\n","\n","x_traincv = cv.fit_transform(x_train)\n","x_traintv = tv.fit_transform(x_train)\n","\n","x_testcv = cv.transform(x_test)\n","x_testtv = tv.transform(x_test)\n","\n","print(\"x train and x test are formed \")\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["x train and x test are formed \n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"NP-nAx84Ybw6"},"source":["# **BASIC TECHNIQUES**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UrdZX-SmraQP","executionInfo":{"status":"ok","timestamp":1620600605513,"user_tz":-330,"elapsed":2341842,"user":{"displayName":"Anvesh Kiran","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjOhw_iYLoY6AZqKmJEWDXO_3Yv2PYAk9BRNjsK8Q=s64","userId":"09289906135724588146"}},"outputId":"c142653a-0b20-4881-ec2a-4bbfb8c028f3"},"source":["######################################################### Basic Techniques\n","\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn import svm\n","from sklearn.linear_model import RidgeClassifier\n","from sklearn.model_selection import GridSearchCV\n","\n","\n","# Hyperparameter tuning for Naive Bayes Classifier\n","mnb=MultinomialNB()\n","list_of_parameters=[]\n","i=2\n","while i<=4 :\n","  i+=0.025\n","  i=round(i,3)\n","  list_of_parameters.append(i)\n","params={'alpha':list_of_parameters}\n","gs=GridSearchCV(estimator=mnb, param_grid=params, cv=5)\n","gs = gs.fit(x_traincv, y_train)\n","best_params=gs.best_params_\n","accuracy=gs.best_score_\n","print(\"For Naive Bayes Classifier (Count Vectorizer) :\")\n","print(\"Best hyperparameter :\", best_params)\n","print('Accuracy of train data :', accuracy)\n","gs = gs.fit(x_traintv, y_train)\n","best_params=gs.best_params_\n","accuracy=gs.best_score_\n","print(\"For Naive Bayes Classifier (Tfid Vectorizer):\")\n","print(\"Best hyperparameter :\", best_params)\n","print('Accuracy of train data :', accuracy)\n","print(\"\")\n","\n","\n","\n","# Hyperparameter tuning for Ridge Classifier\n","clf = RidgeClassifier()\n","list_of_parameters_for_alpha=[]\n","list_of_parameters_for_tol=[]\n","i=3\n","list_of_parameters_for_alpha.append(i)\n","while i<=5 :\n","  i+=0.025\n","  i=round(i,3)\n","  list_of_parameters_for_alpha.append(i)\n","i=0\n","while i<=0.0045 :\n","  i+=0.0005\n","  i=round(i,4)\n","  list_of_parameters_for_tol.append(i)\n","params={'alpha':list_of_parameters_for_alpha, 'tol':list_of_parameters_for_tol}\n","gs=GridSearchCV(estimator=clf, param_grid=params, cv=5)\n","gs = gs.fit(x_traincv, y_train)\n","best_params=gs.best_params_\n","accuracy=gs.best_score_\n","print(\"\")\n","print(\"For Ridge Classifier (Count Vectorizer):\")\n","print(\"Best hyperparameter :\", best_params)\n","print('Accuracy of train data :', accuracy)\n","gs = gs.fit(x_traintv, y_train)\n","best_params=gs.best_params_\n","accuracy=gs.best_score_\n","print(\"For Ridge Classifier (Tfid Vectorizer):\")\n","print(\"Best hyperparameter :\", best_params)\n","print('Accuracy of train data :', accuracy)\n","print(\"\")\n","\n","\n","\n","\n","# Hyperparameter tuning for SVM\n","clf = svm.SVC()\n","list_of_parameters_for_C=[]\n","list_of_parameters_for_tol=[]\n","i=0\n","while i<=2 :\n","  i+=1\n","  list_of_parameters_for_C.append(i)\n","list_of_parameters_for_kernel=[\"linear\", \"rbf\", \"sigmoid\"]\n","i=0\n","while i<=0.0045 :\n","  i+=0.0015\n","  i=round(i,4)\n","  list_of_parameters_for_tol.append(i)\n","params={'C':list_of_parameters_for_C, 'kernel':list_of_parameters_for_kernel, 'tol':list_of_parameters_for_tol}\n","gs=GridSearchCV(estimator=clf, param_grid=params, cv=5)\n","gs = gs.fit(x_traincv, y_train)\n","best_params=gs.best_params_\n","accuracy=gs.best_score_\n","print(\"\")\n","print(\"For SVM (Count Vectorizer):\")\n","print(\"Best hyperparameter :\", best_params)\n","print('Accuracy of train data :', accuracy)\n","gs = gs.fit(x_traintv, y_train)\n","best_params=gs.best_params_\n","accuracy=gs.best_score_\n","print(\"For SVM (Tfid Vectorizer):\")\n","print(\"Best hyperparameter :\", best_params)\n","print('Accuracy of train data :', accuracy)\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["For Naive Bayes Classifier (Count Vectorizer) :\n","Best hyperparameter : {'alpha': 3.875}\n","Accuracy of train data : 0.7107626986297706\n","For Naive Bayes Classifier (Tfid Vectorizer):\n","Best hyperparameter : {'alpha': 2.025}\n","Accuracy of train data : 0.724555070176695\n","\n","\n","For Ridge Classifier (Count Vectorizer):\n","Best hyperparameter : {'alpha': 5.025, 'tol': 0.0025}\n","Accuracy of train data : 0.6873843294624777\n","For Ridge Classifier (Tfid Vectorizer):\n","Best hyperparameter : {'alpha': 4.25, 'tol': 0.001}\n","Accuracy of train data : 0.7133917686149216\n","\n","\n","For SVM (Count Vectorizer):\n","Best hyperparameter : {'C': 1, 'kernel': 'rbf', 'tol': 0.0015}\n","Accuracy of train data : 0.7196959800794304\n","For SVM (Tfid Vectorizer):\n","Best hyperparameter : {'C': 1, 'kernel': 'sigmoid', 'tol': 0.006}\n","Accuracy of train data : 0.708928794834871\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"EpTuzpMO0X59"},"source":["# **ACCURACY METRICS**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jxrjAjXa0oQQ","executionInfo":{"status":"ok","timestamp":1620601325070,"user_tz":-330,"elapsed":34198,"user":{"displayName":"Anvesh Kiran","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjOhw_iYLoY6AZqKmJEWDXO_3Yv2PYAk9BRNjsK8Q=s64","userId":"09289906135724588146"}},"outputId":"77bfbac2-5a45-4a24-c524-51d4245ba4c2"},"source":["from sklearn.naive_bayes import MultinomialNB\n","from sklearn import svm\n","from sklearn.linear_model import RidgeClassifier\n","from sklearn.model_selection import cross_val_predict\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import f1_score\n","from sklearn.metrics import confusion_matrix\n","\n","\n","#Naive Bayes\n","print(\"Naive Bayes Classifier :\")\n","mnb=MultinomialNB(alpha=3.875)\n","y_pred = cross_val_predict(mnb, x_traintv, y_train, cv=5)\n","accuracy = accuracy_score(y_train, y_pred)\n","print(\"Accuracy :\", accuracy)\n","f1 = f1_score(y_train, y_pred)\n","print(\"F1 Score :\", f1)\n","conf_mat = confusion_matrix(y_train, y_pred)\n","print(\"Confusion Matrix :\")\n","print(conf_mat)\n","print(\"\")\n","\n","\n","#SVM\n","print(\"SVM :\")\n","clf = svm.SVC(C=1, kernel='rbf', tol=0.0015)\n","y_pred = cross_val_predict(clf, x_traincv, y_train, cv=5)\n","accuracy = accuracy_score(y_train, y_pred)\n","print(\"Accuracy :\", accuracy)\n","f1 = f1_score(y_train, y_pred)\n","print(\"F1 Score :\", f1)\n","conf_mat = confusion_matrix(y_train, y_pred)\n","print(\"Confusion Matrix :\")\n","print(conf_mat)\n","print(\"\")\n","\n","\n","#Ridge Classifier\n","print(\"Ridge Classifier :\")\n","clf = RidgeClassifier(alpha=4.25, tol= 0.001)\n","y_pred = cross_val_predict(clf, x_traintv, y_train, cv=5)\n","accuracy = accuracy_score(y_train, y_pred)\n","print(\"Accuracy :\", accuracy)\n","f1 = f1_score(y_train, y_pred)\n","print(\"F1 Score :\", f1)\n","conf_mat = confusion_matrix(y_train, y_pred)\n","print(\"Confusion Matrix :\")\n","print(conf_mat)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Naive Bayes Classifier :\n","Accuracy : 0.7120714567187705\n","F1 Score : 0.5497124075595727\n","Confusion Matrix :\n","[[4083  259]\n"," [1933 1338]]\n","\n","SVM :\n","Accuracy : 0.7196900039406279\n","F1 Score : 0.5961392884178652\n","Confusion Matrix :\n","[[3904  438]\n"," [1696 1575]]\n","\n","Ridge Classifier :\n","Accuracy : 0.7133849993432287\n","F1 Score : 0.5829510703363915\n","Confusion Matrix :\n","[[3906  436]\n"," [1746 1525]]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"5nbdGVKvJ1X2"},"source":["# **Submission File**"]},{"cell_type":"code","metadata":{"id":"b7vrZpqVJztr"},"source":["'''\n","x_test=test_df[\"text\"]\n","x_testcv=cv.transform(x_test)\n","mnb.fit(x_traincv, y_train)\n","y_pred=list(mnb.predict(x_testcv))\n","id_arr=list(test_df[\"id\"])\n","target_arr=y_pred\n","df = pd.DataFrame(list(zip(id_arr, target_arr)),columns =['id', 'target'])\n","df.to_csv(r'/content/drive/My Drive/ML_data/submission_file.csv', index=False)\n","'''"],"execution_count":null,"outputs":[]}]}